{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e853e3b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c37ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3eb99",
   "metadata": {},
   "source": [
    "# Function for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b9dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL():\n",
    "    \n",
    "    #initializing the variables\n",
    "    def __init__(self,Netflix_file,Filepath,Filepath_df):\n",
    "        \n",
    "        #assigning csv file to Netflix_file variable \n",
    "        self.Netflix_file = Netflix_file\n",
    "        \n",
    "        #assigning a address to save the cleaned data\n",
    "        self.Filepath = Filepath\n",
    "        \n",
    "        #assigning a address to save the df data frame\n",
    "        self.Filepath_df = Filepath_df\n",
    "        \n",
    "        #downloading Netflix datset\n",
    "        self.data = pd.read_csv(self.Netflix_file)\n",
    "        \n",
    "        #saving columns in a differnt dataset for better result visualization\n",
    "        self.df = self.data[['title','description','listed_in']]\n",
    "        \n",
    "        \n",
    "    #Data Loading\n",
    "    def load_data(self):\n",
    "    \n",
    "        #printing the shape of our data set \n",
    "        print('The data has {} data points and {} features \\n'.format(self.data.shape[0],self.data.shape[1]))\n",
    "        \n",
    "        #keeping just the pertinent features\n",
    "        self.data = self.data[['title','country','director','cast','listed_in','description']]\n",
    "\n",
    "        print('The data after removing irrelevant features has {} and it contains these {} features. The \\\n",
    "        names of the features are {} \\n \\n'.format(self.data.shape[0],self.data.shape[1],list(self.data.columns)))\n",
    "    \n",
    "    #Data Analysis\n",
    "    def analysis(self):\n",
    "    \n",
    "        #Basic stats for directors\n",
    "        print('The basic statistics for the directors of movies are as follows:\\n{}\\n\\n'\n",
    "              .format(self.data['director'].describe()))\n",
    "\n",
    "        #Most common director names\n",
    "        print('The directors with most movies are:\\n{}\\n\\n'.format(Counter(list(self.data['director'])).most_common(10)))\n",
    "\n",
    "        #% of movies with listed directors\n",
    "        print('The percentage of total movies with listed directors:\\n{}% \\n\\n'\n",
    "              .format(self.data[~self.data['director'].isnull()].shape[0]/self.data.shape[0]*100))\n",
    "\n",
    "        #Basic stats for cast\n",
    "        print('The basic statistics for the cast are as follows: \\n{}\\n\\n'\n",
    "              .format(self.data['cast'].describe()))\n",
    "\n",
    "        #% of movies with listed cast\n",
    "        print('The percentage of total movies with listed cast:\\n{}% \\n\\n'\n",
    "              .format(self.data[~self.data['cast'].isnull()].shape[0]/self.data.shape[0]*100))\n",
    "\n",
    "        #movies with missing name\n",
    "        print('The basic statisitcs for movie titles:\\n{}\\n\\n'.format(self.data['title'].describe()))\n",
    "\n",
    "        #movies with missing name\n",
    "        print('The number of movies with missing movie titles:\\n{}\\n\\n'\n",
    "              .format(self.data[self.data['title'].isnull()].shape[0]))\n",
    "\n",
    "        #movies with missing description\n",
    "        print('The number of movies with missing movie description:\\n{}\\n\\n'\n",
    "              .format(self.data[self.data['description'].isnull()].shape[0]))\n",
    "            \n",
    "    #Data cleaning    \n",
    "    def data_cleaning(self):\n",
    "    \n",
    "        #There is no missing movies titles and missing description data\n",
    "        #There is enough text information about the movie even with missing movie cast and \n",
    "        #(continued) director to create relevant vectors after text vectorization\n",
    "        #Replacing the null cast and director columns with blank string\n",
    "        self.data.fillna(\" \",inplace=True)\n",
    "        print('Replacing the null values in director and cast feature with a blank string to create a text \\\n",
    "        feature contaning all relevant data in the form  of a string.\\n\\n')\n",
    "        \n",
    "        #saving stopwords\n",
    "        stopword = set(stopwords.words('english'))\n",
    "        \n",
    "        #removing stopwords, terms which are not alphanumeric and lowering text\n",
    "        for index,rows in self.data.iterrows():\n",
    "            strng = \"\"\n",
    "            #text_preprocessing(self.data['description'].loc[index],index,'description',self.stopword,self.data)\n",
    "            for words in self.data['description'].loc[index].split():\n",
    "                \n",
    "                #removing special characters \n",
    "                word = (\"\".join(i for i in words if i.isalnum()))\n",
    "\n",
    "                #lowering the words\n",
    "                word = word.lower()\n",
    "\n",
    "                #removing stopwords\n",
    "                if word not in stopword:\n",
    "                    strng += word + \" \" \n",
    "            self.data['description'][index] = strng\n",
    "\n",
    "        #keeping just the top three cast names and joining their first names and surnames\n",
    "        self.data['cast'] = self.data['cast'].map(lambda x : x.replace(' ','').lower().split(',')[:3])\n",
    "\n",
    "        #seprating the listed_in category\n",
    "        self.data['listed_in'] = self.data['listed_in'].map(lambda x : x.lower().split(','))\n",
    "\n",
    "        #joining the director surnames and first names\n",
    "        self.data['director'] = self.data['director'].map(lambda x: x.replace(' ','').lower().split(','))\n",
    "\n",
    "        #country\n",
    "        self.data['country'] = self.data['country'].map(lambda x : x.replace(' ','').lower().split(','))\n",
    "\n",
    "        #making a list of description\n",
    "        self.data['description'] = self.data['description'].map(lambda x : x.split(' '))\n",
    "\n",
    "        #Form a column text such that it contains all the columns merged in string format\n",
    "        self.data['text'] = ''\n",
    "        column = list(self.data.columns)\n",
    "        column.remove('title')        \n",
    "        \n",
    "        #forming a column 'text' such that it contains all merged columns\n",
    "        for index,rows in self.data.iterrows():\n",
    "            words = ''\n",
    "            for col in column:\n",
    "                words = words + ' '.join(rows[col]) + ' '\n",
    "            self.data['text'][index] = words    \n",
    "\n",
    "        #removing double spaces from the new text string and making them a single space \n",
    "        self.data['text'] = self.data['text'].map(lambda x : x.replace('  ',' '))\n",
    "        \n",
    "        self.data = self.data[['title','text']] \n",
    "    \n",
    "    #Save Data method    \n",
    "    def save_data(self):\n",
    "    \n",
    "        #saving data in a pickle file\n",
    "        self.data.to_pickle(self.Filepath)\n",
    "\n",
    "        #saving data in a pickle file\n",
    "        self.df.to_pickle(self.Filepath_df)\n",
    "    \n",
    "    #Final method\n",
    "    def processed(self):\n",
    "    \n",
    "        print('LOADING DATA...{}\\n\\n '.format(self.Netflix_file))\n",
    "        self.load_data()\n",
    "\n",
    "        print('DATA ANALYSIS...\\n\\n')\n",
    "        self.analysis()\n",
    "        \n",
    "        print('CLEANING DATA...\\n\\n')\n",
    "        self.data_cleaning()\n",
    "        \n",
    "        print('SAVING DATA IN PICKLE FILE PREPROCESSED {}...\\n\\n'.format(self.Filepath))\n",
    "        self.save_data()\n",
    "        \n",
    "        print('\\n\\n Cleaned data saved to pickle file preprocessed in Pickle folder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
