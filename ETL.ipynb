{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e853e3b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c37ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b9dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL:\n",
    "    \n",
    "    #initializing the variables\n",
    "    def __init__(self,Netflix_file,Filepath,Filepath_df):\n",
    "        \n",
    "        #assigning csv file to Netflix_file variable \n",
    "        self.Netflix_file = Netflix_file\n",
    "        \n",
    "        #assigning a address to save the cleaned data\n",
    "        self.Filepath = Filepath\n",
    "        \n",
    "        #assigning a address to save the df data frame\n",
    "        self.Filepath_df = Filepath_df\n",
    "        \n",
    "        #downloading Netflix datset\n",
    "        self.data = pd.read_csv(self.Netflix_file)\n",
    "        \n",
    "        #saving columns in a differnt dataset for better result visualization\n",
    "        self.df = self.data[['title','description','listed_in']]\n",
    "        \n",
    "        #defining stopwords used in data cleaning\n",
    "        self.stopword = set(stopwords.words('english'))\n",
    "        \n",
    "        #assigning a string variable to be used in stopword removal in data cleaning\n",
    "        self.strng = \"\"\n",
    "        \n",
    "    #Data Loading\n",
    "    def load_data(self):\n",
    "    \n",
    "        #printing the shape of our data set \n",
    "        print('The data has {} data points and {} features \\n'.format(self.data.shape[0],self.data.shape[1]))\n",
    "        \n",
    "        #keeping just the pertinent features\n",
    "        self.data = self.data[['title','country','director','cast','listed_in','description']]\n",
    "\n",
    "        print('The data after removing irrelevant features has {} and it contains these {} features. The names of the features are {} \\n \\n'.format(self.data.shape[0],self.data.shape[1],list(self.data.columns)))\n",
    "    \n",
    "    #Data Analysis\n",
    "    def analysis(self):\n",
    "    \n",
    "        #Basic stats for directors\n",
    "        print('The basic statistics for the directors of movies are as follows: \\n{}\\n\\n'.format(self.data['director'].describe()))\n",
    "\n",
    "        #Most common director names\n",
    "        print('The directors with most movies are:\\n{}\\n\\n'.format(Counter(list(self.data['director'])).most_common(10)))\n",
    "\n",
    "        #% of movies with listed directors\n",
    "        print('The percentage of total movies with listed directors:\\n{}% \\n\\n'.format(self.data[~self.data['director'].isnull()].shape[0]/self.data.shape[0]*100))\n",
    "\n",
    "        #Basic stats for cast\n",
    "        print('The basic statistics for the cast are as follows: \\n{}\\n\\n'.format(self.data['cast'].describe()))\n",
    "\n",
    "        #% of movies with listed cast\n",
    "        print('The percentage of total movies with listed cast:\\n{}% \\n\\n'.format(self.data[~self.data['cast'].isnull()].shape[0]/self.data.shape[0]*100))\n",
    "\n",
    "        #movies with missing name\n",
    "        print('The basic statisitcs for movie titles:\\n{}\\n\\n'.format(self.data['title'].describe()))\n",
    "\n",
    "        #movies with missing name\n",
    "        print('The number of movies with missing movie titles:\\n{}\\n\\n'.format(self.data[self.data['title'].isnull()].shape[0]))\n",
    "\n",
    "        #movies with missing description\n",
    "        print('The number of movies with missing movie description:\\n{}\\n\\n'.format(self.data[self.data['description'].isnull()].shape[0]))\n",
    "\n",
    "            \n",
    "    #Data cleaning    \n",
    "    def data_cleaning(self):\n",
    "    \n",
    "        #There is no missing movies titles and missing description data\n",
    "        #There is enough text information about the movie even with missing movie cast and director to create relevant vectors after text vectorization\n",
    "        #Replacing the null cast and director columns with blank string\n",
    "        self.data.fillna(\" \",inplace=True)\n",
    "        print('Replacing the null values in director and cast feature with a blank string to create a text feature contaning all relevant data in the form  of a string.\\n\\n')\n",
    "\n",
    "        #removing stopwords, terms which are not alphanumeric and lowering text\n",
    "        for index,rows in self.data.iterrows():\n",
    "            for words in rows['description'].split():\n",
    "                #removing special characters \n",
    "                word = (\"\".join(i for i in words if i.isalnum()))\n",
    "\n",
    "                #lowering the words\n",
    "                word = word.lower()\n",
    "\n",
    "                #removing stopwords\n",
    "                if word not in self.stopword:\n",
    "                    self.strng += word + \" \"         \n",
    "            self.data['description'].loc[index] = self.strng\n",
    "        \n",
    "        #keeping just the top three cast names and joining their first names and surnames\n",
    "        self.data['cast'] = self.data['cast'].map(lambda x : x.replace(' ','').lower().split(',')[:3])\n",
    "\n",
    "        #seprating the listed_in category\n",
    "        self.data['listed_in'] = self.data['listed_in'].map(lambda x : x.lower().split(','))\n",
    "\n",
    "        #joining the director surnames and first names\n",
    "        self.data['director'] = self.data['director'].map(lambda x: x.replace(' ','').lower().split(','))\n",
    "\n",
    "        #country\n",
    "        self.data['country'] = self.data['country'].map(lambda x : x.replace(' ','').lower().split(' '))\n",
    "\n",
    "        #making a list of description\n",
    "        self.data['description']= self.data['description'].map(lambda x : x.split(' '))\n",
    "\n",
    "        #Form a column text such that it contains all the columns merged in string format\n",
    "        self.data['text'] = ''\n",
    "        column = list(self.data.columns)\n",
    "        column.remove('title')        \n",
    "        \n",
    "        for index,rows in self.data.iterrows():\n",
    "            words = ''\n",
    "            for col in column:\n",
    "                    words = words + ' '.join(rows[col]) + ' '\n",
    "            self.data['text'][index] = words\n",
    "\n",
    "        #removing double spaces from the new text string and making them a single space \n",
    "        self.data['text'] = self.data['text'].map(lambda x : x.replace('  ',' '))\n",
    "        self.data = self.data[['title','text']] \n",
    "\n",
    "        print('The remaning data is as follows:/n{}/n/n'.format(self.data.head()))\n",
    "    \n",
    "    #Save Data method    \n",
    "    def save_data(self):\n",
    "    \n",
    "        #saving data in a pickle file\n",
    "        self.data.to_pickle(self.Filepath)\n",
    "\n",
    "        #saving data in a pickle file\n",
    "        self.df.to_pickle(self.Filepath_df)\n",
    "    \n",
    "    #Final method\n",
    "    def processed(self):\n",
    "    \n",
    "        print('LOADING DATA...{}\\n\\n '.format(self.Netflix_file))\n",
    "        self.load_data()\n",
    "\n",
    "        print('DATA ANALYSIS...\\n\\n')\n",
    "        self.analysis()\n",
    "        \n",
    "        print('CLEANING DATA...\\n\\n')\n",
    "        self.data_cleaning()\n",
    "        \n",
    "        print('SAVING DATA IN PICKLE FILE PREPROCESSED {}...\\n\\n'.format(self.Filepath))\n",
    "        self.save_data()\n",
    "        \n",
    "        print('\\n\\n Cleaned data saved to pickle file preprocessed in Pickle folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a3a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA...netflix_titles.csv\n",
      "\n",
      " \n",
      "The data has 7787 data points and 12 features \n",
      "\n",
      "The data after removing irrelevant features has 7787 and it contains these 6 features. The names of the features are ['title', 'country', 'director', 'cast', 'listed_in', 'description'] \n",
      " \n",
      "\n",
      "DATA ANALYSIS...\n",
      "\n",
      "\n",
      "The basic statistics for the directors of movies are as follows: \n",
      "count                       5398\n",
      "unique                      4049\n",
      "top       Raúl Campos, Jan Suter\n",
      "freq                          18\n",
      "Name: director, dtype: object\n",
      "\n",
      "\n",
      "The directors with most movies are:\n",
      "[(nan, 2389), ('Raúl Campos, Jan Suter', 18), ('Marcus Raboy', 16), ('Jay Karas', 14), ('Cathy Garcia-Molina', 13), ('Youssef Chahine', 12), ('Martin Scorsese', 12), ('Jay Chapman', 12), ('Steven Spielberg', 10), ('David Dhawan', 9)]\n",
      "\n",
      "\n",
      "The percentage of total movies with listed directors:\n",
      "69.32066264286631% \n",
      "\n",
      "\n",
      "The basic statistics for the cast are as follows: \n",
      "count                   7069\n",
      "unique                  6831\n",
      "top       David Attenborough\n",
      "freq                      18\n",
      "Name: cast, dtype: object\n",
      "\n",
      "\n",
      "The percentage of total movies with listed cast:\n",
      "90.77950430204187% \n",
      "\n",
      "\n",
      "The basic statisitcs for movie titles:\n",
      "count                 7787\n",
      "unique                7787\n",
      "top       Women of Mafia 2\n",
      "freq                     1\n",
      "Name: title, dtype: object\n",
      "\n",
      "\n",
      "The number of movies with missing movie titles:\n",
      "0\n",
      "\n",
      "\n",
      "The number of movies with missing movie description:\n",
      "0\n",
      "\n",
      "\n",
      "CLEANING DATA...\n",
      "\n",
      "\n",
      "Replacing the null values in director and cast feature with a blank string to create a text feature contaning all relevant data in the form  of a string.\n",
      "\n",
      "\n",
      "The remaning data is as follows:/n   title                                               text\n",
      "0     3%  brazil joãomiguel biancacomparato michelgomes ...\n",
      "1   7:19  mexico jorgemichelgrau demiánbichir héctorboni...\n",
      "2  23:59  singapore gilbertchan teddchan stellachung hen...\n",
      "3      9  unitedstates shaneacker elijahwood johnc.reill...\n",
      "4     21  unitedstates robertluketic jimsturgess kevinsp.../n/n\n",
      "SAVING DATA IN PICKLE FILE PREPROCESSED Pickle/preprocessed_data...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Cleaned data saved to pickle file preprocessed in Pickle folder\n"
     ]
    }
   ],
   "source": [
    "#extract_transform_load = ETL('netflix_titles.csv','Pickle/preprocessed_data','Pickle/original_data')\n",
    "#extract_transform_load.processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19986f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
